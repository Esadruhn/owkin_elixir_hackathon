{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23321321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "#!pip install opencv-python \n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce3752c",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34f9a98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_images = '../data/ML/train/target_0'\n",
    "tumor_images = '../data/ML/train/target_1'\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba5c540a",
   "metadata": {},
   "outputs": [],
   "source": [
    "healthy_loaded = load_images_from_folder(healthy_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0061dc23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3618"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(healthy_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef65e63d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "healthy_loaded[3000].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39ca5528",
   "metadata": {},
   "outputs": [],
   "source": [
    "tumor_loaded = load_images_from_folder(tumor_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09dd98bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1382"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tumor_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "237589d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tumor_loaded[300].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a4a2c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random\n",
    "\n",
    "root_dir = '/home/user/data/ML/train' # data root path\n",
    "classes_names = ['target_0', 'target_1']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c81fb74",
   "metadata": {},
   "source": [
    "## Split in train/test/val folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde5e11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dirs():\n",
    "    \n",
    "    for cls in classes_names:\n",
    "        os.makedirs(os.path.join(root_dir, 'train', cls))\n",
    "        os.makedirs(os.path.join(root_dir, 'val', cls))\n",
    "        os.makedirs(os.path.join(root_dir, 'test', cls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1c020f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ratio = 0.05\n",
    "val_ratio = 0.15\n",
    "\n",
    "\n",
    "all_healthy_filenames = os.listdir(os.path.join(root_dir,classes_names[0]))\n",
    "\n",
    "np.random.shuffle(all_healthy_filenames)\n",
    "train_healthy, val_healthy, test_healthy = np.split(np.array(all_healthy_filenames),\n",
    "                                                          [int(len(all_healthy_filenames)* (1 - (val_ratio + test_ratio))), \n",
    "                                                           int(len(all_healthy_filenames)* (1 - test_ratio))])\n",
    "\n",
    "\n",
    "train_healthy = [os.path.join(root_dir, classes_names[0], name) for name in train_healthy]\n",
    "val_healthy = [os.path.join(root_dir, classes_names[0],  name) for name in val_healthy]\n",
    "test_healthy = [os.path.join(root_dir, classes_names[0], name) for name in test_healthy]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d924c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data_healthy():\n",
    "    for name in train_healthy:\n",
    "        shutil.copy(name, os.path.join(root_dir, 'train', classes_names[0]))\n",
    "    for name in test_healthy:\n",
    "        shutil.copy(name, os.path.join(root_dir, 'test', classes_names[0]))\n",
    "    for name in val_healthy:\n",
    "        shutil.copy(name, os.path.join(root_dir, 'val', classes_names[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e703d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images:  3618\n",
      "Training:  2894\n",
      "Validation:  543\n",
      "Testing:  181\n"
     ]
    }
   ],
   "source": [
    "print('Total images: ', len(all_healthy_filenames))\n",
    "print('Training: ', len(train_healthy))\n",
    "print('Validation: ', len(val_healthy))\n",
    "print('Testing: ', len(test_healthy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e4e1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tumor_filenames = os.listdir(os.path.join(root_dir,classes_names[1]))\n",
    "\n",
    "np.random.shuffle(all_tumor_filenames)\n",
    "train_tumor, val_tumor, test_tumor = np.split(np.array(all_tumor_filenames),\n",
    "                                                          [int(len(all_tumor_filenames)* (1 - (val_ratio + test_ratio))), \n",
    "                                                           int(len(all_tumor_filenames)* (1 - test_ratio))])\n",
    "\n",
    "\n",
    "train_tumor = [os.path.join(root_dir, classes_names[1], name) for name in train_tumor]\n",
    "val_tumor = [os.path.join(root_dir, classes_names[1],  name) for name in val_tumor]\n",
    "test_tumor = [os.path.join(root_dir, classes_names[1], name) for name in test_tumor]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f7c1dd50",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total images:  1382\n",
      "Training:  1105\n",
      "Validation:  207\n",
      "Testing:  70\n"
     ]
    }
   ],
   "source": [
    "print('Total images: ', len(all_tumor_filenames))\n",
    "print('Training: ', len(train_tumor))\n",
    "print('Validation: ', len(val_tumor))\n",
    "print('Testing: ', len(test_tumor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f76d1d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_data_tumor():\n",
    "    for name in train_tumor:\n",
    "        shutil.copy(name, os.path.join(root_dir, 'train', classes_names[1]))\n",
    "    for name in val_tumor:\n",
    "        shutil.copy(name, os.path.join(root_dir, 'test', classes_names[1]))\n",
    "    for name in test_tumor:\n",
    "        shutil.copy(name, os.path.join(root_dir, 'val', classes_names[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0a3f595",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tumor_check = os.listdir(os.path.join(root_dir,'train', classes_names[1]))\n",
    "len(train_tumor_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa0c364",
   "metadata": {},
   "source": [
    "## Add augmentations (so far None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4449578f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add augmentations\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    \n",
    "    'val': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        \n",
    "    ]),    \n",
    "    'test': transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fcf58c",
   "metadata": {},
   "source": [
    "## Create DataSet and DataLoader for Training and Val Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a2c30cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/user/data/ML/train'\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
    "                  for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c250febe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': Dataset ImageFolder\n",
       "     Number of datapoints: 3999\n",
       "     Root location: /home/user/data/ML/train/train\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            ),\n",
       " 'val': Dataset ImageFolder\n",
       "     Number of datapoints: 613\n",
       "     Root location: /home/user/data/ML/train/val\n",
       "     StandardTransform\n",
       " Transform: Compose(\n",
       "                ToTensor()\n",
       "            )}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6eb164c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=1,\n",
    "                                             shuffle=True, num_workers=0)\n",
    "              for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79d01e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['target_0', 'target_1']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
    "class_names = image_datasets['train'].classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9cf9704e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': 3999, 'val': 613}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "967aaa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3999"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataloaders['train'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd1f1d2",
   "metadata": {},
   "source": [
    "## Create DataSet and DataLoader for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b10bc195",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "test_data_path = '/home/user/data/test'\n",
    "classes_names = ['target_0', 'target_1']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6b7b1153",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datasets = {'test': datasets.ImageFolder(os.path.join(test_data_path), data_transforms['test'])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c36ee026",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = {'test': torch.utils.data.DataLoader(image_datasets['test'], batch_size=1,\n",
    "                                             shuffle=True, num_workers=0)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b2479585",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022b8aa",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "17b4abe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_save, criterion, optimizer, scheduler, num_epochs=4):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    \n",
    "    PATH = model_save\n",
    "    torch.save(best_model_wts, PATH)\n",
    "        \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d5432cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, saved_weights, criterion, optimizer, scheduler):\n",
    "    \n",
    "    model.load_state_dict(torch.load(saved_weights))\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    predictions = np.array([])\n",
    "    labels =  np.array([])\n",
    "            \n",
    "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader['test']:\n",
    "            images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(images)\n",
    "            # the class with the highest energy is what we choose as prediction\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            sigmoid = torch.sigmoid(outputs)    \n",
    "            print(sigmoid)\n",
    "\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56501e7a",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ba87af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = models.resnet18(pretrained=True)\n",
    "num_ftrs = model_ft.fc.in_features\n",
    "\n",
    "# Here the size of each output sample is set to 2.\n",
    "model_ft.fc = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.Adam(model_ft.parameters(), lr=0.001)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "af85a005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/3\n",
      "----------\n",
      "train Loss: 0.6338 Acc: 0.7054\n",
      "val Loss: 0.4059 Acc: 0.8858\n",
      "\n",
      "Epoch 1/3\n",
      "----------\n",
      "train Loss: 0.6141 Acc: 0.7157\n",
      "val Loss: 0.4370 Acc: 0.8858\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n",
      "train Loss: 0.5931 Acc: 0.7247\n",
      "val Loss: 0.3559 Acc: 0.8858\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n",
      "train Loss: 0.5316 Acc: 0.7567\n",
      "val Loss: 0.4506 Acc: 0.8858\n",
      "\n",
      "Training complete in 4m 55s\n",
      "Best val Acc: 0.885808\n"
     ]
    }
   ],
   "source": [
    "# train \n",
    "model_ft = train_model(model_ft, \"resnet_best_model_weights.pth\", criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "248c6b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6545, 0.3498]], device='cuda:0')\n",
      "tensor([[0.6396, 0.3620]], device='cuda:0')\n",
      "tensor([[0.6349, 0.3545]], device='cuda:0')\n",
      "tensor([[0.6545, 0.3503]], device='cuda:0')\n",
      "tensor([[0.6523, 0.3516]], device='cuda:0')\n",
      "tensor([[0.6253, 0.3470]], device='cuda:0')\n",
      "tensor([[0.6283, 0.3470]], device='cuda:0')\n",
      "tensor([[0.6330, 0.3544]], device='cuda:0')\n",
      "tensor([[0.6552, 0.3486]], device='cuda:0')\n",
      "tensor([[0.6259, 0.3457]], device='cuda:0')\n",
      "tensor([[0.6327, 0.3573]], device='cuda:0')\n",
      "tensor([[0.6373, 0.3622]], device='cuda:0')\n",
      "tensor([[0.6242, 0.3447]], device='cuda:0')\n",
      "tensor([[0.6419, 0.3591]], device='cuda:0')\n",
      "tensor([[0.6518, 0.3560]], device='cuda:0')\n",
      "tensor([[0.6549, 0.3492]], device='cuda:0')\n",
      "tensor([[0.6536, 0.3514]], device='cuda:0')\n",
      "tensor([[0.6450, 0.3569]], device='cuda:0')\n",
      "tensor([[0.6448, 0.3573]], device='cuda:0')\n",
      "tensor([[0.6525, 0.3552]], device='cuda:0')\n",
      "tensor([[0.6418, 0.3585]], device='cuda:0')\n",
      "tensor([[0.6526, 0.3531]], device='cuda:0')\n",
      "tensor([[0.6256, 0.3463]], device='cuda:0')\n",
      "tensor([[0.6260, 0.3520]], device='cuda:0')\n",
      "tensor([[0.6532, 0.3508]], device='cuda:0')\n",
      "tensor([[0.6403, 0.3657]], device='cuda:0')\n",
      "tensor([[0.6367, 0.3535]], device='cuda:0')\n",
      "tensor([[0.6522, 0.3524]], device='cuda:0')\n",
      "tensor([[0.6406, 0.3578]], device='cuda:0')\n",
      "tensor([[0.6398, 0.3535]], device='cuda:0')\n",
      "tensor([[0.6271, 0.3462]], device='cuda:0')\n",
      "tensor([[0.6266, 0.3473]], device='cuda:0')\n",
      "tensor([[0.6402, 0.3577]], device='cuda:0')\n",
      "tensor([[0.6528, 0.3545]], device='cuda:0')\n",
      "tensor([[0.6556, 0.3481]], device='cuda:0')\n",
      "tensor([[0.6331, 0.3567]], device='cuda:0')\n",
      "tensor([[0.6543, 0.3503]], device='cuda:0')\n",
      "tensor([[0.6409, 0.3577]], device='cuda:0')\n",
      "tensor([[0.6369, 0.3623]], device='cuda:0')\n",
      "tensor([[0.6502, 0.3568]], device='cuda:0')\n",
      "tensor([[0.6560, 0.3477]], device='cuda:0')\n",
      "tensor([[0.6358, 0.3628]], device='cuda:0')\n",
      "tensor([[0.6275, 0.3463]], device='cuda:0')\n",
      "tensor([[0.6327, 0.3570]], device='cuda:0')\n",
      "tensor([[0.6547, 0.3493]], device='cuda:0')\n",
      "tensor([[0.6382, 0.3658]], device='cuda:0')\n",
      "tensor([[0.6383, 0.3579]], device='cuda:0')\n",
      "tensor([[0.6245, 0.3491]], device='cuda:0')\n",
      "tensor([[0.6358, 0.3500]], device='cuda:0')\n",
      "tensor([[0.6359, 0.3632]], device='cuda:0')\n",
      "tensor([[0.6572, 0.3460]], device='cuda:0')\n",
      "tensor([[0.6315, 0.3489]], device='cuda:0')\n",
      "tensor([[0.6479, 0.3566]], device='cuda:0')\n",
      "tensor([[0.6525, 0.3553]], device='cuda:0')\n",
      "tensor([[0.6359, 0.3631]], device='cuda:0')\n",
      "tensor([[0.6347, 0.3557]], device='cuda:0')\n",
      "tensor([[0.6531, 0.3531]], device='cuda:0')\n",
      "tensor([[0.6409, 0.3579]], device='cuda:0')\n",
      "tensor([[0.6571, 0.3461]], device='cuda:0')\n",
      "tensor([[0.6540, 0.3508]], device='cuda:0')\n",
      "tensor([[0.6333, 0.3523]], device='cuda:0')\n",
      "tensor([[0.6500, 0.3553]], device='cuda:0')\n",
      "tensor([[0.6319, 0.3578]], device='cuda:0')\n",
      "tensor([[0.6345, 0.3601]], device='cuda:0')\n",
      "tensor([[0.6333, 0.3571]], device='cuda:0')\n",
      "tensor([[0.6564, 0.3470]], device='cuda:0')\n",
      "tensor([[0.6238, 0.3366]], device='cuda:0')\n",
      "tensor([[0.6529, 0.3540]], device='cuda:0')\n",
      "tensor([[0.6284, 0.3528]], device='cuda:0')\n",
      "tensor([[0.6314, 0.3551]], device='cuda:0')\n",
      "tensor([[0.6380, 0.3590]], device='cuda:0')\n",
      "tensor([[0.6353, 0.3605]], device='cuda:0')\n",
      "tensor([[0.6567, 0.3467]], device='cuda:0')\n",
      "tensor([[0.6275, 0.3540]], device='cuda:0')\n",
      "tensor([[0.6321, 0.3553]], device='cuda:0')\n",
      "tensor([[0.6446, 0.3573]], device='cuda:0')\n",
      "tensor([[0.6486, 0.3547]], device='cuda:0')\n",
      "tensor([[0.6564, 0.3474]], device='cuda:0')\n",
      "tensor([[0.6517, 0.3528]], device='cuda:0')\n",
      "tensor([[0.6389, 0.3531]], device='cuda:0')\n",
      "tensor([[0.6364, 0.3556]], device='cuda:0')\n",
      "tensor([[0.6400, 0.3586]], device='cuda:0')\n",
      "tensor([[0.6560, 0.3474]], device='cuda:0')\n",
      "tensor([[0.6563, 0.3472]], device='cuda:0')\n",
      "tensor([[0.6449, 0.3578]], device='cuda:0')\n",
      "tensor([[0.6500, 0.3565]], device='cuda:0')\n",
      "tensor([[0.6533, 0.3528]], device='cuda:0')\n",
      "tensor([[0.6361, 0.3579]], device='cuda:0')\n",
      "tensor([[0.6558, 0.3477]], device='cuda:0')\n",
      "tensor([[0.6312, 0.3539]], device='cuda:0')\n",
      "tensor([[0.6310, 0.3535]], device='cuda:0')\n",
      "tensor([[0.6265, 0.3500]], device='cuda:0')\n",
      "tensor([[0.6345, 0.3607]], device='cuda:0')\n",
      "tensor([[0.6338, 0.3613]], device='cuda:0')\n",
      "tensor([[0.6365, 0.3619]], device='cuda:0')\n",
      "tensor([[0.6287, 0.3500]], device='cuda:0')\n",
      "tensor([[0.6401, 0.3579]], device='cuda:0')\n",
      "tensor([[0.6461, 0.3567]], device='cuda:0')\n",
      "tensor([[0.6236, 0.3488]], device='cuda:0')\n",
      "tensor([[0.6530, 0.3538]], device='cuda:0')\n",
      "tensor([[0.6334, 0.3604]], device='cuda:0')\n",
      "tensor([[0.6303, 0.3568]], device='cuda:0')\n",
      "tensor([[0.6379, 0.3543]], device='cuda:0')\n",
      "tensor([[0.6509, 0.3564]], device='cuda:0')\n",
      "tensor([[0.6408, 0.3583]], device='cuda:0')\n",
      "tensor([[0.6357, 0.3604]], device='cuda:0')\n",
      "tensor([[0.6530, 0.3539]], device='cuda:0')\n",
      "tensor([[0.6533, 0.3528]], device='cuda:0')\n",
      "tensor([[0.6309, 0.3571]], device='cuda:0')\n",
      "tensor([[0.6526, 0.3553]], device='cuda:0')\n",
      "tensor([[0.6564, 0.3470]], device='cuda:0')\n",
      "tensor([[0.6474, 0.3570]], device='cuda:0')\n",
      "tensor([[0.6532, 0.3521]], device='cuda:0')\n",
      "tensor([[0.6360, 0.3639]], device='cuda:0')\n",
      "tensor([[0.6576, 0.3455]], device='cuda:0')\n",
      "tensor([[0.6391, 0.3541]], device='cuda:0')\n",
      "tensor([[0.6357, 0.3607]], device='cuda:0')\n",
      "tensor([[0.6240, 0.3410]], device='cuda:0')\n",
      "tensor([[0.6398, 0.3546]], device='cuda:0')\n",
      "tensor([[0.6546, 0.3491]], device='cuda:0')\n",
      "tensor([[0.6414, 0.3613]], device='cuda:0')\n",
      "tensor([[0.6320, 0.3595]], device='cuda:0')\n",
      "tensor([[0.6558, 0.3478]], device='cuda:0')\n",
      "tensor([[0.6311, 0.3554]], device='cuda:0')\n",
      "tensor([[0.6331, 0.3577]], device='cuda:0')\n",
      "tensor([[0.6540, 0.3488]], device='cuda:0')\n",
      "tensor([[0.6408, 0.3597]], device='cuda:0')\n",
      "tensor([[0.6532, 0.3520]], device='cuda:0')\n",
      "tensor([[0.6387, 0.3663]], device='cuda:0')\n",
      "tensor([[0.6382, 0.3652]], device='cuda:0')\n",
      "tensor([[0.6523, 0.3541]], device='cuda:0')\n",
      "tensor([[0.6488, 0.3543]], device='cuda:0')\n",
      "tensor([[0.6315, 0.3548]], device='cuda:0')\n",
      "tensor([[0.6306, 0.3571]], device='cuda:0')\n",
      "tensor([[0.6259, 0.3499]], device='cuda:0')\n",
      "tensor([[0.6370, 0.3632]], device='cuda:0')\n",
      "tensor([[0.6292, 0.3533]], device='cuda:0')\n",
      "tensor([[0.6381, 0.3559]], device='cuda:0')\n",
      "tensor([[0.6560, 0.3476]], device='cuda:0')\n",
      "tensor([[0.6412, 0.3567]], device='cuda:0')\n",
      "tensor([[0.6354, 0.3602]], device='cuda:0')\n",
      "tensor([[0.6317, 0.3517]], device='cuda:0')\n",
      "tensor([[0.6379, 0.3654]], device='cuda:0')\n",
      "tensor([[0.6329, 0.3544]], device='cuda:0')\n",
      "tensor([[0.6355, 0.3546]], device='cuda:0')\n",
      "tensor([[0.6499, 0.3573]], device='cuda:0')\n",
      "tensor([[0.6535, 0.3515]], device='cuda:0')\n",
      "tensor([[0.6524, 0.3549]], device='cuda:0')\n",
      "tensor([[0.6293, 0.3538]], device='cuda:0')\n",
      "tensor([[0.6293, 0.3490]], device='cuda:0')\n",
      "tensor([[0.6355, 0.3609]], device='cuda:0')\n",
      "tensor([[0.6405, 0.3576]], device='cuda:0')\n",
      "tensor([[0.6323, 0.3477]], device='cuda:0')\n",
      "tensor([[0.6541, 0.3511]], device='cuda:0')\n",
      "tensor([[0.6416, 0.3619]], device='cuda:0')\n",
      "tensor([[0.6506, 0.3539]], device='cuda:0')\n",
      "tensor([[0.6337, 0.3586]], device='cuda:0')\n",
      "tensor([[0.6409, 0.3576]], device='cuda:0')\n",
      "tensor([[0.6287, 0.3512]], device='cuda:0')\n",
      "tensor([[0.6553, 0.3485]], device='cuda:0')\n",
      "tensor([[0.6545, 0.3498]], device='cuda:0')\n",
      "tensor([[0.6329, 0.3559]], device='cuda:0')\n",
      "tensor([[0.6437, 0.3578]], device='cuda:0')\n",
      "tensor([[0.6382, 0.3599]], device='cuda:0')\n",
      "tensor([[0.6353, 0.3600]], device='cuda:0')\n",
      "tensor([[0.6448, 0.3592]], device='cuda:0')\n",
      "tensor([[0.6402, 0.3562]], device='cuda:0')\n",
      "tensor([[0.6363, 0.3595]], device='cuda:0')\n",
      "tensor([[0.6348, 0.3580]], device='cuda:0')\n",
      "tensor([[0.6410, 0.3583]], device='cuda:0')\n",
      "tensor([[0.6292, 0.3454]], device='cuda:0')\n",
      "tensor([[0.6290, 0.3540]], device='cuda:0')\n",
      "tensor([[0.6526, 0.3552]], device='cuda:0')\n",
      "tensor([[0.6438, 0.3581]], device='cuda:0')\n",
      "tensor([[0.6316, 0.3565]], device='cuda:0')\n",
      "tensor([[0.6379, 0.3554]], device='cuda:0')\n",
      "tensor([[0.6339, 0.3600]], device='cuda:0')\n",
      "tensor([[0.6412, 0.3582]], device='cuda:0')\n",
      "tensor([[0.6345, 0.3616]], device='cuda:0')\n",
      "tensor([[0.6250, 0.3481]], device='cuda:0')\n",
      "tensor([[0.6249, 0.3504]], device='cuda:0')\n",
      "tensor([[0.6466, 0.3562]], device='cuda:0')\n",
      "tensor([[0.6432, 0.3636]], device='cuda:0')\n",
      "tensor([[0.6293, 0.3490]], device='cuda:0')\n",
      "tensor([[0.6286, 0.3477]], device='cuda:0')\n",
      "tensor([[0.6239, 0.3504]], device='cuda:0')\n",
      "tensor([[0.6391, 0.3566]], device='cuda:0')\n",
      "tensor([[0.6524, 0.3553]], device='cuda:0')\n",
      "tensor([[0.6394, 0.3567]], device='cuda:0')\n",
      "tensor([[0.6420, 0.3563]], device='cuda:0')\n",
      "tensor([[0.6401, 0.3578]], device='cuda:0')\n",
      "tensor([[0.6405, 0.3580]], device='cuda:0')\n",
      "tensor([[0.6388, 0.3563]], device='cuda:0')\n",
      "tensor([[0.6282, 0.3481]], device='cuda:0')\n",
      "tensor([[0.6337, 0.3574]], device='cuda:0')\n",
      "tensor([[0.6313, 0.3516]], device='cuda:0')\n",
      "tensor([[0.6420, 0.3594]], device='cuda:0')\n",
      "tensor([[0.6309, 0.3588]], device='cuda:0')\n",
      "tensor([[0.6380, 0.3626]], device='cuda:0')\n",
      "tensor([[0.6348, 0.3597]], device='cuda:0')\n",
      "tensor([[0.6525, 0.3553]], device='cuda:0')\n",
      "tensor([[0.6527, 0.3552]], device='cuda:0')\n",
      "tensor([[0.6516, 0.3556]], device='cuda:0')\n",
      "tensor([[0.6550, 0.3491]], device='cuda:0')\n",
      "tensor([[0.6525, 0.3551]], device='cuda:0')\n",
      "tensor([[0.6265, 0.3529]], device='cuda:0')\n",
      "tensor([[0.6339, 0.3602]], device='cuda:0')\n",
      "tensor([[0.6378, 0.3648]], device='cuda:0')\n",
      "tensor([[0.6370, 0.3641]], device='cuda:0')\n",
      "tensor([[0.6429, 0.3626]], device='cuda:0')\n",
      "tensor([[0.6327, 0.3575]], device='cuda:0')\n",
      "tensor([[0.6562, 0.3473]], device='cuda:0')\n",
      "tensor([[0.6427, 0.3587]], device='cuda:0')\n",
      "tensor([[0.6302, 0.3569]], device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5728/3554624697.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mPATH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./_best_val_model_weights.pth'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_ft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_lr_scheduler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_5728/2464397252.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_loader, saved_weights, criterion, optimizer, scheduler)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# since we're not training, we don't need to calculate the gradients for our outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/elixenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/elixenv/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/elixenv/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/elixenv/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/elixenv/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \"\"\"\n\u001b[1;32m    231\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/elixenv/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/elixenv/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    249\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/elixenv/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    913\u001b[0m         \"\"\"\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m         \u001b[0mhas_transparency\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"transparency\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/elixenv/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 255\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#test \n",
    "PATH = './_best_val_model_weights.pth'\n",
    "\n",
    "predictions = test(model_ft, test_loader, PATH, criterion, optimizer_ft, exp_lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299acc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.DataFrame(data={'file_paths': file_paths, 'predictions': predictions})\n",
    "df_submission[\"file_paths\"] = df_submission[\"file_paths\"].apply(lambda x: x.replace(\"/home/user/data/test\",\"/data/challenges_data/test\"))\n",
    "\n",
    "df_submission.to_csv('df_submission.csv', index=False)\n",
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b98639",
   "metadata": {},
   "source": [
    "## DenseNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b59f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_ft = models.densenet161(pretrained=True)\n",
    "num_ftrs = model_ft.classifier.in_features\n",
    "# Here the size of each output sample is set to 2.\n",
    "# Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
    "model_ft.classifier = nn.Linear(num_ftrs, 2)\n",
    "\n",
    "model_ft = model_ft.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# Decay LR by a factor of 0.1 every 7 epochs\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7865b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train \n",
    "model_ft = train_model(model_ft, \"densenet_best_model_weights.pth\", criterion, optimizer_ft, exp_lr_scheduler,\n",
    "                       num_epochs=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2adc23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test \n",
    "PATH = './densenet_best_model_weights.pth'\n",
    "\n",
    "predictions = test(model_ft, test_loader, PATH, criterion, optimizer_ft, exp_lr_scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd17bd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 08:35:45.247863: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5519/133953308.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_ds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c72d131",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'file_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5519/4155462280.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_submission\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'file_paths'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfile_paths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'predictions'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_paths\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_submission\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"file_paths\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/home/user/data/test\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"/data/challenges_data/test\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'file_paths' is not defined"
     ]
    }
   ],
   "source": [
    "df_submission = pd.DataFrame(data={'file_paths': file_paths, 'predictions': predictions})\n",
    "df_submission[\"file_paths\"] = df_submission[\"file_paths\"].apply(lambda x: x.replace(\"/home/user/data/test\",\"/data/challenges_data/test\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e64fb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.to_csv('df_submission.csv', index=False)\n",
    "df_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elixenv",
   "language": "python",
   "name": "elixenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
