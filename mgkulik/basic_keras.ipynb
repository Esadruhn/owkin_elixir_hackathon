{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ba65bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "train_path = '/home/user/data/data/ML/train'\n",
    "validation_path = '/home/user/data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f0c21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Checking the image sizes\n",
    "img = Image.open('/home/user/data/data/ML/train/target_1/tumor_0_9_9178.jpg')\n",
    "print(img.size)\n",
    "\n",
    "image_size = (180,180)\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "eval_all, mdl_lst, aug_lst = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28920b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAugment(object):\n",
    "    def __call__(self, image):        \n",
    "        # Random flips and grayscale with some stochasticity\n",
    "        img = self._random_apply(tf.image.flip_left_right, image, p=0.6)\n",
    "        img = self._random_apply(self._color_drop, img, p=0.9)\n",
    "        return img\n",
    "\n",
    "    def _color_drop(self, x):\n",
    "        image = tf.image.rgb_to_grayscale(x)\n",
    "        image = tf.tile(x, [1, 1, 1, 3])\n",
    "        return x\n",
    "    \n",
    "    def _random_apply(self, func, x, p):\n",
    "        return tf.cond(\n",
    "          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
    "                  tf.cast(p, tf.float32)),\n",
    "          lambda: func(x),\n",
    "          lambda: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405758da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 files belonging to 2 classes.\n",
      "Using 4000 files for training.\n",
      "Found 6000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 16:28:06.595336: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-11 16:28:06.610207: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-11 16:28:06.611370: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-11 16:28:06.613146: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-11 16:28:06.615037: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-11 16:28:06.616039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-11 16:28:06.616979: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-11 16:28:07.197910: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-11 16:28:07.198918: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-11 16:28:07.199893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-11 16:28:07.200797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15405 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=train_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=0,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=validation_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    shuffle=False,\n",
    "    seed=0,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed46c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(buffer_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b25be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_augmentation(input_shape):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "    return x, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b66ab741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_basic_model(num_classes, x, inputs):\n",
    "    \n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e56819f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_effB3_model(x, inputs):\n",
    "    \n",
    "    effB3_model = tf.keras.applications.EfficientNetB3(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=image_size + (3,),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "    effB3_model.trainable = False\n",
    "    \n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = effB3_model(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f62b95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_effB7_model(x, inputs):\n",
    "    \n",
    "    effB7_model = tf.keras.applications.EfficientNetB7(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=image_size + (3,),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "    effB7_model.trainable = False\n",
    "    \n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = effB7_model(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caf99176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vgg16_model(x, inputs):\n",
    "    \n",
    "    vgg16_model = tf.keras.applications.VGG16(\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=image_size + (3,),\n",
    "        include_top=False)\n",
    "    vgg16_model.trainable = False\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = vgg16_model(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97090b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rn152v2_model(x, inputs):\n",
    "    \n",
    "    rn152v2_model = tf.keras.applications.ResNet152V2(\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=image_size + (3,),\n",
    "        include_top=False)\n",
    "    rn152v2_model.trainable = False\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = rn152v2_model(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "385803ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dn201_model(x, inputs):\n",
    "    \n",
    "    dn201_model = tf.keras.applications.DenseNet201(\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=image_size + (3,),\n",
    "        include_top=False)\n",
    "    dn201_model.trainable = False\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = dn201_model(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bab09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_model(model, train_ds, test_ds, group, seq, mod_type):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.AUC()],\n",
    "    )\n",
    "    model.fit(train_ds, epochs=epochs)\n",
    "    eval_lst = [seq]+model.evaluate(train_ds)+model.evaluate(test_ds)+[group, mod_type]\n",
    "    \n",
    "    return model, eval_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ff2c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_lst = [\"flip_rotation\", \"flip_color_rot\", \"flip_color_rot_zoom\", \n",
    "             \"flip_color_rot_zoom_gn\", \"flip_color_rot_zoom_cont\", \"flipHV_color_rot_zoom_cont\"]\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.RandomFlip(\"horizontal\"),\n",
    "                                 layers.RandomRotation(0.1)]))\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.Lambda(CustomAugment()),\n",
    "                                 layers.RandomRotation(0.1)]))\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.Lambda(CustomAugment()),\n",
    "                                 layers.RandomRotation(0.1),\n",
    "                                 layers.RandomZoom(0.1)]))\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.Lambda(CustomAugment()),\n",
    "                                 layers.RandomRotation(0.1),\n",
    "                                 layers.RandomZoom(0.1),\n",
    "                                 layers.GaussianNoise(0.1)]))\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.Lambda(CustomAugment()),\n",
    "                                 layers.RandomRotation(0.1),\n",
    "                                 layers.RandomZoom(0.1),\n",
    "                                 layers.GaussianNoise(0.1),\n",
    "                                 layers.RandomContrast(0.2)]))\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.RandomRotation(0.1),\n",
    "                                 layers.RandomZoom(0.1),\n",
    "                                 layers.GaussianNoise(0.1),\n",
    "                                 layers.RandomContrast(0.2),\n",
    "                                 layers.RandomFlip(\"horizontal_and_vertical\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6e7167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mod_type = [\"basic\", \"effB3\", \"vgg16\", \"resnet152v2\", \"denseNet201\", \"effB7\"]\n",
    "mod_type = [\"effB3\", \"effB7\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e35c4229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-11 16:28:19.800900: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-11 16:28:21.488288: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 17s 54ms/step - loss: 0.3778 - binary_accuracy: 0.8465 - auc: 0.8732\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2758 - binary_accuracy: 0.9038 - auc: 0.9220\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2557 - binary_accuracy: 0.9087 - auc: 0.9310\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2433 - binary_accuracy: 0.9128 - auc: 0.9370\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2344 - binary_accuracy: 0.9150 - auc: 0.9418\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 7s 55ms/step - loss: 0.2269 - binary_accuracy: 0.9187 - auc: 0.9452\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2207 - binary_accuracy: 0.9200 - auc: 0.9487\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2149 - binary_accuracy: 0.9230 - auc: 0.9523\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2109 - binary_accuracy: 0.9237 - auc: 0.9543\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2072 - binary_accuracy: 0.9260 - auc: 0.9555\n",
      "125/125 [==============================] - 9s 54ms/step - loss: 0.2065 - binary_accuracy: 0.9287 - auc: 0.9605\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.2757 - binary_accuracy: 0.8988 - auc: 0.9431\n",
      "\n",
      "Model: 1\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n",
      "258080768/258076736 [==============================] - 8s 0us/step\n",
      "258088960/258076736 [==============================] - 8s 0us/step\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 38s 164ms/step - loss: 0.3923 - binary_accuracy: 0.8430 - auc_1: 0.8750\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 21s 164ms/step - loss: 0.3095 - binary_accuracy: 0.8880 - auc_1: 0.9121\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2891 - binary_accuracy: 0.8950 - auc_1: 0.9212\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 21s 164ms/step - loss: 0.2768 - binary_accuracy: 0.9003 - auc_1: 0.9269\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2673 - binary_accuracy: 0.9032 - auc_1: 0.9317\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2624 - binary_accuracy: 0.9010 - auc_1: 0.9343\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2564 - binary_accuracy: 0.9050 - auc_1: 0.9370\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2515 - binary_accuracy: 0.9080 - auc_1: 0.9393\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2473 - binary_accuracy: 0.9085 - auc_1: 0.9414\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2441 - binary_accuracy: 0.9107 - auc_1: 0.9429\n",
      "125/125 [==============================] - 25s 163ms/step - loss: 0.2374 - binary_accuracy: 0.9122 - auc_1: 0.9470\n",
      "188/188 [==============================] - 31s 164ms/step - loss: 0.3126 - binary_accuracy: 0.8772 - auc_1: 0.9355\n",
      "\n",
      "Model: 2\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 15s 54ms/step - loss: 0.3692 - binary_accuracy: 0.8547 - auc_2: 0.8787\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2749 - binary_accuracy: 0.9013 - auc_2: 0.9236\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2529 - binary_accuracy: 0.9095 - auc_2: 0.9343\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2410 - binary_accuracy: 0.9135 - auc_2: 0.9397\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2329 - binary_accuracy: 0.9165 - auc_2: 0.9435\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2256 - binary_accuracy: 0.9187 - auc_2: 0.9470\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2188 - binary_accuracy: 0.9193 - auc_2: 0.9508\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2144 - binary_accuracy: 0.9237 - auc_2: 0.9527\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2097 - binary_accuracy: 0.9247 - auc_2: 0.9556\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2062 - binary_accuracy: 0.9262 - auc_2: 0.9567\n",
      "125/125 [==============================] - 9s 54ms/step - loss: 0.2022 - binary_accuracy: 0.9262 - auc_2: 0.9601\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.2785 - binary_accuracy: 0.8968 - auc_2: 0.9430\n",
      "\n",
      "Model: 3\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 38s 163ms/step - loss: 0.4086 - binary_accuracy: 0.8357 - auc_3: 0.8605\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.3129 - binary_accuracy: 0.8870 - auc_3: 0.9108\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2938 - binary_accuracy: 0.8917 - auc_3: 0.9190\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2773 - binary_accuracy: 0.8985 - auc_3: 0.9268\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2702 - binary_accuracy: 0.8995 - auc_3: 0.9303\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2645 - binary_accuracy: 0.9028 - auc_3: 0.9332\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2575 - binary_accuracy: 0.9053 - auc_3: 0.9360\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2524 - binary_accuracy: 0.9082 - auc_3: 0.9393\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2471 - binary_accuracy: 0.9093 - auc_3: 0.9415\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2460 - binary_accuracy: 0.9110 - auc_3: 0.9417\n",
      "125/125 [==============================] - 25s 163ms/step - loss: 0.2376 - binary_accuracy: 0.9107 - auc_3: 0.9464\n",
      "188/188 [==============================] - 31s 162ms/step - loss: 0.3221 - binary_accuracy: 0.8758 - auc_3: 0.9347\n",
      "\n",
      "Model: 4\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 15s 54ms/step - loss: 0.3548 - binary_accuracy: 0.8645 - auc_4: 0.8882\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2692 - binary_accuracy: 0.9040 - auc_4: 0.9267\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2526 - binary_accuracy: 0.9097 - auc_4: 0.9332\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2393 - binary_accuracy: 0.9130 - auc_4: 0.9407\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2311 - binary_accuracy: 0.9158 - auc_4: 0.9447\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2237 - binary_accuracy: 0.9190 - auc_4: 0.9482\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2185 - binary_accuracy: 0.9190 - auc_4: 0.9508\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2136 - binary_accuracy: 0.9215 - auc_4: 0.9536\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2082 - binary_accuracy: 0.9245 - auc_4: 0.9562\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2056 - binary_accuracy: 0.9255 - auc_4: 0.9570\n",
      "125/125 [==============================] - 9s 54ms/step - loss: 0.2000 - binary_accuracy: 0.9295 - auc_4: 0.9613\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.2795 - binary_accuracy: 0.8955 - auc_4: 0.9429\n",
      "\n",
      "Model: 5\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 37s 163ms/step - loss: 0.4091 - binary_accuracy: 0.8303 - auc_5: 0.8623\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.3153 - binary_accuracy: 0.8860 - auc_5: 0.9093\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2925 - binary_accuracy: 0.8928 - auc_5: 0.9191\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2786 - binary_accuracy: 0.8995 - auc_5: 0.9258\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2704 - binary_accuracy: 0.9015 - auc_5: 0.9299\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2644 - binary_accuracy: 0.9032 - auc_5: 0.9329\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2571 - binary_accuracy: 0.9035 - auc_5: 0.9366\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2517 - binary_accuracy: 0.9068 - auc_5: 0.9391\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2477 - binary_accuracy: 0.9082 - auc_5: 0.9410\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2448 - binary_accuracy: 0.9093 - auc_5: 0.9421\n",
      "125/125 [==============================] - 25s 163ms/step - loss: 0.2378 - binary_accuracy: 0.9115 - auc_5: 0.9467\n",
      "188/188 [==============================] - 31s 162ms/step - loss: 0.3168 - binary_accuracy: 0.8783 - auc_5: 0.9346\n",
      "\n",
      "Model: 6\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 15s 54ms/step - loss: 0.3601 - binary_accuracy: 0.8593 - auc_6: 0.8857\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2725 - binary_accuracy: 0.9022 - auc_6: 0.9236\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2519 - binary_accuracy: 0.9085 - auc_6: 0.9336\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2413 - binary_accuracy: 0.9125 - auc_6: 0.9380\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2333 - binary_accuracy: 0.9150 - auc_6: 0.9424\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2241 - binary_accuracy: 0.9190 - auc_6: 0.9470\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2187 - binary_accuracy: 0.9208 - auc_6: 0.9504\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2141 - binary_accuracy: 0.9237 - auc_6: 0.9520\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 7s 55ms/step - loss: 0.2086 - binary_accuracy: 0.9222 - auc_6: 0.9557\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 7s 55ms/step - loss: 0.2059 - binary_accuracy: 0.9245 - auc_6: 0.9562\n",
      "125/125 [==============================] - 9s 54ms/step - loss: 0.1997 - binary_accuracy: 0.9293 - auc_6: 0.9606\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.2793 - binary_accuracy: 0.8957 - auc_6: 0.9439\n",
      "\n",
      "Model: 7\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 38s 163ms/step - loss: 0.4071 - binary_accuracy: 0.8317 - auc_7: 0.8629\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.3137 - binary_accuracy: 0.8842 - auc_7: 0.9104\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2902 - binary_accuracy: 0.8928 - auc_7: 0.9209\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2764 - binary_accuracy: 0.8995 - auc_7: 0.9277\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2687 - binary_accuracy: 0.9005 - auc_7: 0.9317\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2615 - binary_accuracy: 0.9038 - auc_7: 0.9346\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2558 - binary_accuracy: 0.9065 - auc_7: 0.9371\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2520 - binary_accuracy: 0.9062 - auc_7: 0.9391\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2480 - binary_accuracy: 0.9100 - auc_7: 0.9414\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2436 - binary_accuracy: 0.9082 - auc_7: 0.9435\n",
      "125/125 [==============================] - 25s 162ms/step - loss: 0.2368 - binary_accuracy: 0.9122 - auc_7: 0.9471\n",
      "188/188 [==============================] - 30s 162ms/step - loss: 0.3162 - binary_accuracy: 0.8785 - auc_7: 0.9354\n",
      "\n",
      "Model: 8\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 15s 54ms/step - loss: 0.3528 - binary_accuracy: 0.8648 - auc_8: 0.8896\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2705 - binary_accuracy: 0.9030 - auc_8: 0.9256\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2513 - binary_accuracy: 0.9082 - auc_8: 0.9345\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2415 - binary_accuracy: 0.9137 - auc_8: 0.9387\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2307 - binary_accuracy: 0.9155 - auc_8: 0.9448\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2256 - binary_accuracy: 0.9180 - auc_8: 0.9464\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2185 - binary_accuracy: 0.9208 - auc_8: 0.9506\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2131 - binary_accuracy: 0.9233 - auc_8: 0.9540\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2097 - binary_accuracy: 0.9235 - auc_8: 0.9551\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2060 - binary_accuracy: 0.9247 - auc_8: 0.9566\n",
      "125/125 [==============================] - 9s 53ms/step - loss: 0.1992 - binary_accuracy: 0.9275 - auc_8: 0.9606\n",
      "188/188 [==============================] - 10s 53ms/step - loss: 0.2852 - binary_accuracy: 0.8933 - auc_8: 0.9429\n",
      "\n",
      "Model: 9\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 38s 163ms/step - loss: 0.4020 - binary_accuracy: 0.8298 - auc_9: 0.8666\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.3122 - binary_accuracy: 0.8870 - auc_9: 0.9112\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2895 - binary_accuracy: 0.8923 - auc_9: 0.9213\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2780 - binary_accuracy: 0.8990 - auc_9: 0.9275\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2686 - binary_accuracy: 0.9022 - auc_9: 0.9311\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2626 - binary_accuracy: 0.9038 - auc_9: 0.9341\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2569 - binary_accuracy: 0.9043 - auc_9: 0.9368\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2537 - binary_accuracy: 0.9093 - auc_9: 0.9383\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.2489 - binary_accuracy: 0.9075 - auc_9: 0.9408\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 21s 164ms/step - loss: 0.2440 - binary_accuracy: 0.9103 - auc_9: 0.9433\n",
      "125/125 [==============================] - 25s 163ms/step - loss: 0.2402 - binary_accuracy: 0.9135 - auc_9: 0.9473\n",
      "188/188 [==============================] - 31s 163ms/step - loss: 0.3095 - binary_accuracy: 0.8777 - auc_9: 0.9354\n",
      "\n",
      "Model: 10\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 15s 55ms/step - loss: 0.3578 - binary_accuracy: 0.8675 - auc_10: 0.8880\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2738 - binary_accuracy: 0.9028 - auc_10: 0.9219\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 7s 55ms/step - loss: 0.2539 - binary_accuracy: 0.9105 - auc_10: 0.9320\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 7s 55ms/step - loss: 0.2411 - binary_accuracy: 0.9140 - auc_10: 0.9384\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 7s 55ms/step - loss: 0.2321 - binary_accuracy: 0.9172 - auc_10: 0.9433\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2254 - binary_accuracy: 0.9187 - auc_10: 0.9468\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 7s 55ms/step - loss: 0.2192 - binary_accuracy: 0.9193 - auc_10: 0.9501\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2143 - binary_accuracy: 0.9220 - auc_10: 0.9525\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2098 - binary_accuracy: 0.9252 - auc_10: 0.9542\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2053 - binary_accuracy: 0.9252 - auc_10: 0.9567\n",
      "125/125 [==============================] - 9s 54ms/step - loss: 0.2000 - binary_accuracy: 0.9300 - auc_10: 0.9611\n",
      "188/188 [==============================] - 10s 55ms/step - loss: 0.2776 - binary_accuracy: 0.8945 - auc_10: 0.9439\n",
      "\n",
      "Model: 11\n",
      "Epoch 1/10\n",
      "125/125 [==============================] - 37s 164ms/step - loss: 0.4085 - binary_accuracy: 0.8325 - auc_11: 0.8636\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 20s 163ms/step - loss: 0.3147 - binary_accuracy: 0.8827 - auc_11: 0.9103\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 21s 164ms/step - loss: 0.2920 - binary_accuracy: 0.8938 - auc_11: 0.9202\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 20s 164ms/step - loss: 0.2783 - binary_accuracy: 0.8978 - auc_11: 0.9263\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 20s 164ms/step - loss: 0.2670 - binary_accuracy: 0.9043 - auc_11: 0.9326\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 21s 164ms/step - loss: 0.2621 - binary_accuracy: 0.9045 - auc_11: 0.9342\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 21s 164ms/step - loss: 0.2565 - binary_accuracy: 0.9080 - auc_11: 0.9368\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 21s 164ms/step - loss: 0.2518 - binary_accuracy: 0.9070 - auc_11: 0.9393\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 21s 164ms/step - loss: 0.2473 - binary_accuracy: 0.9097 - auc_11: 0.9414\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 21s 164ms/step - loss: 0.2450 - binary_accuracy: 0.9100 - auc_11: 0.9427\n",
      "125/125 [==============================] - 25s 163ms/step - loss: 0.2368 - binary_accuracy: 0.9118 - auc_11: 0.9469\n",
      "188/188 [==============================] - 31s 163ms/step - loss: 0.3156 - binary_accuracy: 0.8792 - auc_11: 0.9362\n",
      "\n",
      "--- 2336.657180786133 seconds ---\n"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "starts_ends = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(0, len(aug_lst)):\n",
    "    for j in mod_type:\n",
    "        print(\"Model: \" + str(k))\n",
    "        data_augmentation = aug_lst[i]\n",
    "        aug_mod, aug_inputs = gen_augmentation(image_size + (3,))\n",
    "        if (j==\"basic\"):\n",
    "            model = make_basic_model(num_classes=2, x=aug_mod, inputs=aug_inputs)\n",
    "        elif (j==\"effB3\"):\n",
    "            model = make_effB3_model(x=aug_mod, inputs=aug_inputs)\n",
    "        elif (j==\"effB7\"):\n",
    "            model = make_effB7_model(x=aug_mod, inputs=aug_inputs)\n",
    "        elif (j==\"vgg16\"):\n",
    "            model = make_vgg16_model(x=aug_mod, inputs=aug_inputs)\n",
    "        elif (j==\"resnet152v2\"):\n",
    "            model = make_rn152v2_model(x=aug_mod, inputs=aug_inputs)\n",
    "        elif (j==\"denseNet201\"):\n",
    "            model = make_dn201_model(x=aug_mod, inputs=aug_inputs)\n",
    "        mdl, eval_lst = execute_model(model, train_ds, test_ds, group_lst[i], k, j)\n",
    "        mdl_lst.append(mdl)\n",
    "        eval_all.append(eval_lst)\n",
    "        k += 1\n",
    "        print()\n",
    "        \n",
    "tot_in_sec = time.time() - start_time\n",
    "print(\"--- %s seconds ---\" % (tot_in_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f7cfed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"id\", \"train_loss\", \"train_bin_acc\", \"train_auc\", \"test_loss\", \"test_bin_acc\", \"test_auc\", \"group\", \"model\"]\n",
    "df_best_model = pd.DataFrame(eval_all,columns=cols)\n",
    "df_best_model = df_best_model.sort_values(\"test_auc\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b9e6e75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_bin_acc</th>\n",
       "      <th>train_auc</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_bin_acc</th>\n",
       "      <th>test_auc</th>\n",
       "      <th>group</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>0.199660</td>\n",
       "      <td>0.92925</td>\n",
       "      <td>0.960642</td>\n",
       "      <td>0.279291</td>\n",
       "      <td>0.895667</td>\n",
       "      <td>0.943940</td>\n",
       "      <td>flip_color_rot_zoom_gn</td>\n",
       "      <td>effB3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.199956</td>\n",
       "      <td>0.93000</td>\n",
       "      <td>0.961093</td>\n",
       "      <td>0.277582</td>\n",
       "      <td>0.894500</td>\n",
       "      <td>0.943887</td>\n",
       "      <td>flipHV_color_rot_zoom_cont</td>\n",
       "      <td>effB3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.206486</td>\n",
       "      <td>0.92875</td>\n",
       "      <td>0.960493</td>\n",
       "      <td>0.275720</td>\n",
       "      <td>0.898833</td>\n",
       "      <td>0.943092</td>\n",
       "      <td>flip_rotation</td>\n",
       "      <td>effB3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0.202157</td>\n",
       "      <td>0.92625</td>\n",
       "      <td>0.960147</td>\n",
       "      <td>0.278508</td>\n",
       "      <td>0.896833</td>\n",
       "      <td>0.942989</td>\n",
       "      <td>flip_color_rot</td>\n",
       "      <td>effB3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.200025</td>\n",
       "      <td>0.92950</td>\n",
       "      <td>0.961340</td>\n",
       "      <td>0.279515</td>\n",
       "      <td>0.895500</td>\n",
       "      <td>0.942892</td>\n",
       "      <td>flip_color_rot_zoom</td>\n",
       "      <td>effB3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>0.199169</td>\n",
       "      <td>0.92750</td>\n",
       "      <td>0.960609</td>\n",
       "      <td>0.285194</td>\n",
       "      <td>0.893333</td>\n",
       "      <td>0.942865</td>\n",
       "      <td>flip_color_rot_zoom_cont</td>\n",
       "      <td>effB3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>11</td>\n",
       "      <td>0.236801</td>\n",
       "      <td>0.91175</td>\n",
       "      <td>0.946909</td>\n",
       "      <td>0.315620</td>\n",
       "      <td>0.879167</td>\n",
       "      <td>0.936167</td>\n",
       "      <td>flipHV_color_rot_zoom_cont</td>\n",
       "      <td>effB7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0.237375</td>\n",
       "      <td>0.91225</td>\n",
       "      <td>0.947022</td>\n",
       "      <td>0.312582</td>\n",
       "      <td>0.877167</td>\n",
       "      <td>0.935460</td>\n",
       "      <td>flip_rotation</td>\n",
       "      <td>effB7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>0.236838</td>\n",
       "      <td>0.91225</td>\n",
       "      <td>0.947104</td>\n",
       "      <td>0.316210</td>\n",
       "      <td>0.878500</td>\n",
       "      <td>0.935365</td>\n",
       "      <td>flip_color_rot_zoom_gn</td>\n",
       "      <td>effB7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.240182</td>\n",
       "      <td>0.91350</td>\n",
       "      <td>0.947257</td>\n",
       "      <td>0.309457</td>\n",
       "      <td>0.877667</td>\n",
       "      <td>0.935361</td>\n",
       "      <td>flip_color_rot_zoom_cont</td>\n",
       "      <td>effB7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0.237640</td>\n",
       "      <td>0.91075</td>\n",
       "      <td>0.946388</td>\n",
       "      <td>0.322061</td>\n",
       "      <td>0.875833</td>\n",
       "      <td>0.934726</td>\n",
       "      <td>flip_color_rot</td>\n",
       "      <td>effB7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>0.237767</td>\n",
       "      <td>0.91150</td>\n",
       "      <td>0.946705</td>\n",
       "      <td>0.316821</td>\n",
       "      <td>0.878333</td>\n",
       "      <td>0.934648</td>\n",
       "      <td>flip_color_rot_zoom</td>\n",
       "      <td>effB7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  train_loss  train_bin_acc  train_auc  test_loss  test_bin_acc  \\\n",
       "0    6    0.199660        0.92925   0.960642   0.279291      0.895667   \n",
       "1   10    0.199956        0.93000   0.961093   0.277582      0.894500   \n",
       "2    0    0.206486        0.92875   0.960493   0.275720      0.898833   \n",
       "3    2    0.202157        0.92625   0.960147   0.278508      0.896833   \n",
       "4    4    0.200025        0.92950   0.961340   0.279515      0.895500   \n",
       "5    8    0.199169        0.92750   0.960609   0.285194      0.893333   \n",
       "6   11    0.236801        0.91175   0.946909   0.315620      0.879167   \n",
       "7    1    0.237375        0.91225   0.947022   0.312582      0.877167   \n",
       "8    7    0.236838        0.91225   0.947104   0.316210      0.878500   \n",
       "9    9    0.240182        0.91350   0.947257   0.309457      0.877667   \n",
       "10   3    0.237640        0.91075   0.946388   0.322061      0.875833   \n",
       "11   5    0.237767        0.91150   0.946705   0.316821      0.878333   \n",
       "\n",
       "    test_auc                       group  model  \n",
       "0   0.943940      flip_color_rot_zoom_gn  effB3  \n",
       "1   0.943887  flipHV_color_rot_zoom_cont  effB3  \n",
       "2   0.943092               flip_rotation  effB3  \n",
       "3   0.942989              flip_color_rot  effB3  \n",
       "4   0.942892         flip_color_rot_zoom  effB3  \n",
       "5   0.942865    flip_color_rot_zoom_cont  effB3  \n",
       "6   0.936167  flipHV_color_rot_zoom_cont  effB7  \n",
       "7   0.935460               flip_rotation  effB7  \n",
       "8   0.935365      flip_color_rot_zoom_gn  effB7  \n",
       "9   0.935361    flip_color_rot_zoom_cont  effB7  \n",
       "10  0.934726              flip_color_rot  effB7  \n",
       "11  0.934648         flip_color_rot_zoom  effB7  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cee14f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = mdl_lst[df_best_model.loc[0, \"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb05a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = test_ds.file_paths\n",
    "\n",
    "def generate_sub_best_model(model, file_paths, save_sub, dtn):\n",
    "    predictions = np.array([])\n",
    "    labels =  np.array([])\n",
    "    for x, y in test_ds:\n",
    "        predictions = np.concatenate([predictions, model.predict(x).ravel()])\n",
    "        labels = np.concatenate([labels, y.numpy().ravel()])\n",
    "    df_solution = pd.DataFrame(data={'file_paths': file_paths, 'predictions': labels})\n",
    "    #df_solution.to_csv('df_solution.csv', index=False)\n",
    "    df_submission = pd.DataFrame(data={'file_paths': file_paths, 'predictions': predictions})\n",
    "    df_submission[\"file_paths\"] = df_submission[\"file_paths\"].apply(lambda x: \n",
    "                                                                    x.replace(\"/home/user/data/test\",\n",
    "                                                                              \"/data/challenges_data/test\"))\n",
    "    \n",
    "    if (save_sub):\n",
    "        df_submission.to_csv('df_submission_'+str(dtn)+'.csv', index=False)\n",
    "        model.save(\"best_model\"+dtn+\".h5\")\n",
    "    return df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0f5b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submissions = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4406d202",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/elixenv/lib/python3.7/site-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "dtn = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "df_submission = generate_sub_best_model(mdl, file_paths, save_submissions, dtn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c215de0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_paths</th>\n",
       "      <th>predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/data/challenges_data/test/target_0/normal_0_1...</td>\n",
       "      <td>0.099915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/data/challenges_data/test/target_0/normal_0_1...</td>\n",
       "      <td>0.015611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/data/challenges_data/test/target_0/normal_0_1...</td>\n",
       "      <td>0.181475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/data/challenges_data/test/target_0/normal_0_1...</td>\n",
       "      <td>0.110315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/data/challenges_data/test/target_0/normal_0_1...</td>\n",
       "      <td>0.135454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          file_paths  predictions\n",
       "0  /data/challenges_data/test/target_0/normal_0_1...     0.099915\n",
       "1  /data/challenges_data/test/target_0/normal_0_1...     0.015611\n",
       "2  /data/challenges_data/test/target_0/normal_0_1...     0.181475\n",
       "3  /data/challenges_data/test/target_0/normal_0_1...     0.110315\n",
       "4  /data/challenges_data/test/target_0/normal_0_1...     0.135454"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
