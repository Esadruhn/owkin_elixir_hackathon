{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "56ba65bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "train_path = '/home/user/data/data/ML/train'\n",
    "validation_path = '/home/user/data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21f0c21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Checking the image sizes\n",
    "img = Image.open('/home/user/data/data/ML/train/target_1/tumor_0_9_9178.jpg')\n",
    "print(img.size)\n",
    "\n",
    "image_size = (180,180)\n",
    "batch_size = 32\n",
    "epochs = 20\n",
    "eval_all, mdl_lst, aug_lst = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28920b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAugment(object):\n",
    "    def __call__(self, image):        \n",
    "        # Random flips and grayscale with some stochasticity\n",
    "        img = self._random_apply(tf.image.flip_left_right, image, p=0.6)\n",
    "        img = self._random_apply(self._color_drop, img, p=0.9)\n",
    "        return img\n",
    "\n",
    "    def _color_drop(self, x):\n",
    "        image = tf.image.rgb_to_grayscale(x)\n",
    "        image = tf.tile(x, [1, 1, 1, 3])\n",
    "        return x\n",
    "    \n",
    "    def _random_apply(self, func, x, p):\n",
    "        return tf.cond(\n",
    "          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
    "                  tf.cast(p, tf.float32)),\n",
    "          lambda: func(x),\n",
    "          lambda: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "405758da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 files belonging to 2 classes.\n",
      "Using 4000 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 23:56:13.181796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 23:56:13.196169: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 23:56:13.197185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 23:56:13.199009: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-10 23:56:13.200858: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 23:56:13.201909: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 23:56:13.202855: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 23:56:13.787572: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 23:56:13.788603: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 23:56:13.789576: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 23:56:13.790459: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15405 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=train_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=0,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=validation_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    shuffle=False,\n",
    "    seed=0,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed46c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(buffer_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b25be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_augmentation(input_shape):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "    return x, inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b66ab741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_basic_model(num_classes, x, inputs):\n",
    "    \n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e56819f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_effB3_model(x, inputs):\n",
    "    \n",
    "    effB3_model = tf.keras.applications.EfficientNetB3(\n",
    "    weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "    input_shape=image_size + (3,),\n",
    "    include_top=False)  # Do not include the ImageNet classifier at the top.\n",
    "\n",
    "    effB3_model.trainable = False\n",
    "    \n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = effB3_model(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "caf99176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_vgg16_model(x, inputs):\n",
    "    \n",
    "    vgg16_model = tf.keras.applications.VGG16(\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=image_size + (3,),\n",
    "        include_top=False)\n",
    "    vgg16_model.trainable = False\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = vgg16_model(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97090b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rn152v2_model(x, inputs):\n",
    "    \n",
    "    rn152v2_model = tf.keras.applications.ResNet152V2(\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=image_size + (3,),\n",
    "        include_top=False)\n",
    "    rn152v2_model.trainable = False\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = rn152v2_model(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "385803ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dn201_model(x, inputs):\n",
    "    \n",
    "    dn201_model = tf.keras.applications.DenseNet201(\n",
    "        weights=\"imagenet\",\n",
    "        input_shape=image_size + (3,),\n",
    "        include_top=False)\n",
    "    dn201_model.trainable = False\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = dn201_model(inputs, training=False)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    outputs = keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9bab09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_model(model, train_ds, test_ds, group, seq, mod_type):\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.AUC()],\n",
    "    )\n",
    "    model.fit(train_ds, epochs=epochs)\n",
    "    eval_lst = [seq]+model.evaluate(train_ds)+model.evaluate(test_ds)+[group, mod_type]\n",
    "    \n",
    "    return model, eval_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ff2c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_lst = [\"flip_rotation\", \"flip_color_rot\", \"flip_color_rot_zoom\", \n",
    "             \"flip_color_rot_zoom_gn\", \"flip_color_rot_zoom_cont\", \"flipHV_color_rot_zoom_cont\"]\n",
    "\n",
    "mod_type = [\"basic\", \"effB3\", \"vgg16\", \"resnet152v2\", \"denseNet201\"]\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.RandomFlip(\"horizontal\"),\n",
    "                                 layers.RandomRotation(0.1)]))\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.Lambda(CustomAugment()),\n",
    "                                 layers.RandomRotation(0.1)]))\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.Lambda(CustomAugment()),\n",
    "                                 layers.RandomRotation(0.1),\n",
    "                                 layers.RandomZoom(0.1)]))\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.Lambda(CustomAugment()),\n",
    "                                 layers.RandomRotation(0.1),\n",
    "                                 layers.RandomZoom(0.1),\n",
    "                                 layers.GaussianNoise(0.1)]))\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.Lambda(CustomAugment()),\n",
    "                                 layers.RandomRotation(0.1),\n",
    "                                 layers.RandomZoom(0.1),\n",
    "                                 layers.GaussianNoise(0.1),\n",
    "                                 layers.RandomContrast(0.2)]))\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.RandomRotation(0.1),\n",
    "                                 layers.RandomZoom(0.1),\n",
    "                                 layers.GaussianNoise(0.1),\n",
    "                                 layers.RandomContrast(0.2),\n",
    "                                 layers.RandomFlip(\"horizontal_and_vertical\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35c4229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 23:56:16.601992: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-10 23:56:17.792189: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 [==============================] - 26s 172ms/step - loss: 0.3751 - binary_accuracy: 0.8530 - auc: 0.8857\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 22s 173ms/step - loss: 0.3140 - binary_accuracy: 0.8865 - auc: 0.9108\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 22s 173ms/step - loss: 0.3133 - binary_accuracy: 0.8895 - auc: 0.9104\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 0.2705 - binary_accuracy: 0.9018 - auc: 0.9308\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 22s 173ms/step - loss: 0.2623 - binary_accuracy: 0.9035 - auc: 0.9307\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 0.2602 - binary_accuracy: 0.9072 - auc: 0.9314\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 0.2387 - binary_accuracy: 0.9170 - auc: 0.9434\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 0.2521 - binary_accuracy: 0.9053 - auc: 0.9400\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 22s 173ms/step - loss: 0.2397 - binary_accuracy: 0.9115 - auc: 0.9457\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 22s 173ms/step - loss: 0.2229 - binary_accuracy: 0.9197 - auc: 0.9501\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 22s 173ms/step - loss: 0.2306 - binary_accuracy: 0.9162 - auc: 0.9508\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 0.2296 - binary_accuracy: 0.9180 - auc: 0.9443\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 0.2199 - binary_accuracy: 0.9205 - auc: 0.9529\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 0.2069 - binary_accuracy: 0.9275 - auc: 0.9552\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 22s 173ms/step - loss: 0.2261 - binary_accuracy: 0.9262 - auc: 0.9476\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 0.2068 - binary_accuracy: 0.9265 - auc: 0.9562\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 0.1951 - binary_accuracy: 0.9298 - auc: 0.9625\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 22s 173ms/step - loss: 0.2011 - binary_accuracy: 0.9270 - auc: 0.9562\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 0.1916 - binary_accuracy: 0.9315 - auc: 0.9613\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 22s 172ms/step - loss: 0.1936 - binary_accuracy: 0.9327 - auc: 0.9595\n",
      "125/125 [==============================] - 4s 30ms/step - loss: 0.2432 - binary_accuracy: 0.9065 - auc: 0.9592\n",
      "188/188 [==============================] - 6s 32ms/step - loss: 1.0960 - binary_accuracy: 0.7483 - auc: 0.8787\n",
      "\n",
      "Model: 1\n",
      "Epoch 1/20\n",
      "125/125 [==============================] - 15s 54ms/step - loss: 0.3645 - binary_accuracy: 0.8550 - auc_1: 0.8814\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2730 - binary_accuracy: 0.9018 - auc_1: 0.9237\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2530 - binary_accuracy: 0.9090 - auc_1: 0.9336\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2414 - binary_accuracy: 0.9125 - auc_1: 0.9389\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2331 - binary_accuracy: 0.9135 - auc_1: 0.9433\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2240 - binary_accuracy: 0.9160 - auc_1: 0.9485\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2187 - binary_accuracy: 0.9205 - auc_1: 0.9508\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2141 - binary_accuracy: 0.9222 - auc_1: 0.9528\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2095 - binary_accuracy: 0.9227 - auc_1: 0.9549\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2046 - binary_accuracy: 0.9245 - auc_1: 0.9576\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.2014 - binary_accuracy: 0.9285 - auc_1: 0.9590\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.1980 - binary_accuracy: 0.9277 - auc_1: 0.9612\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.1953 - binary_accuracy: 0.9298 - auc_1: 0.9618\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.1930 - binary_accuracy: 0.9315 - auc_1: 0.9625\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.1907 - binary_accuracy: 0.9300 - auc_1: 0.9631\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.1879 - binary_accuracy: 0.9325 - auc_1: 0.9649\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.1844 - binary_accuracy: 0.9330 - auc_1: 0.9665\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.1831 - binary_accuracy: 0.9348 - auc_1: 0.9668\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.1812 - binary_accuracy: 0.9355 - auc_1: 0.9675\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 7s 54ms/step - loss: 0.1782 - binary_accuracy: 0.9370 - auc_1: 0.9692\n",
      "125/125 [==============================] - 9s 53ms/step - loss: 0.1740 - binary_accuracy: 0.9398 - auc_1: 0.9714\n",
      "188/188 [==============================] - 10s 54ms/step - loss: 0.2951 - binary_accuracy: 0.8910 - auc_1: 0.9378\n",
      "\n",
      "Model: 2\n",
      "Epoch 1/20\n",
      "125/125 [==============================] - 8s 44ms/step - loss: 0.6587 - binary_accuracy: 0.8140 - auc_2: 0.8423\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.3754 - binary_accuracy: 0.8777 - auc_2: 0.8971\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.3258 - binary_accuracy: 0.8925 - auc_2: 0.9123\n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.2878 - binary_accuracy: 0.9055 - auc_2: 0.9226\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.2705 - binary_accuracy: 0.9072 - auc_2: 0.9308\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.2448 - binary_accuracy: 0.9172 - auc_2: 0.9383\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.2322 - binary_accuracy: 0.9202 - auc_2: 0.9433\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.2233 - binary_accuracy: 0.9208 - auc_2: 0.9478\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.2192 - binary_accuracy: 0.9268 - auc_2: 0.9495\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.2095 - binary_accuracy: 0.9277 - auc_2: 0.9532\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.2099 - binary_accuracy: 0.9247 - auc_2: 0.9546\n",
      "Epoch 12/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.2025 - binary_accuracy: 0.9277 - auc_2: 0.9574\n",
      "Epoch 13/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.2022 - binary_accuracy: 0.9298 - auc_2: 0.9566\n",
      "Epoch 14/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.1955 - binary_accuracy: 0.9302 - auc_2: 0.9607\n",
      "Epoch 15/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.1905 - binary_accuracy: 0.9348 - auc_2: 0.9620\n",
      "Epoch 16/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.1874 - binary_accuracy: 0.9350 - auc_2: 0.9627\n",
      "Epoch 17/20\n",
      "125/125 [==============================] - 5s 44ms/step - loss: 0.1918 - binary_accuracy: 0.9312 - auc_2: 0.9617\n",
      "Epoch 18/20\n",
      "125/125 [==============================] - 5s 44ms/step - loss: 0.1854 - binary_accuracy: 0.9367 - auc_2: 0.9635\n",
      "Epoch 19/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.1862 - binary_accuracy: 0.9330 - auc_2: 0.9650\n",
      "Epoch 20/20\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.1831 - binary_accuracy: 0.9348 - auc_2: 0.9645\n",
      "125/125 [==============================] - 6s 43ms/step - loss: 0.1725 - binary_accuracy: 0.9398 - auc_2: 0.9710\n",
      "188/188 [==============================] - 9s 50ms/step - loss: 0.4521 - binary_accuracy: 0.8502 - auc_2: 0.9073\n",
      "\n",
      "Model: 3\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234553344/234545216 [==============================] - 7s 0us/step\n",
      "234561536/234545216 [==============================] - 7s 0us/step\n",
      "Epoch 1/20\n",
      "125/125 [==============================] - 22s 103ms/step - loss: 8.2562 - binary_accuracy: 0.7240 - auc_3: 0.6728\n",
      "Epoch 2/20\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 4.1234 - binary_accuracy: 0.7355 - auc_3: 0.69882s - loss: 4.2303 - binary_accurac\n",
      "Epoch 3/20\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 5.7203 - binary_accuracy: 0.7245 - auc_3: 0.67312s - loss: 4.9896 - binary_accuracy: 0.7381 - auc_3: - ETA: 2s - loss: 4.9740 - binary_accuracy: \n",
      "Epoch 4/20\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 4.8457 - binary_accuracy: 0.7673 - auc_3: 0.72642s - loss: 5.0658 - binary_accurac\n",
      "Epoch 5/20\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 4.7734 - binary_accuracy: 0.7470 - auc_3: 0.7126\n",
      "Epoch 6/20\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 3.0122 - binary_accuracy: 0.7925 - auc_3: 0.7682\n",
      "Epoch 7/20\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 3.7142 - binary_accuracy: 0.7623 - auc_3: 0.7290\n",
      "Epoch 8/20\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 3.8540 - binary_accuracy: 0.7617 - auc_3: 0.7299\n",
      "Epoch 9/20\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 4.8796 - binary_accuracy: 0.7722 - auc_3: 0.73642s - loss: 5.3687 - binary_accuracy: 0.7621 - auc_3:  - ETA: 1s - loss: 5.2180 - binary_accuracy: 0.7655 - auc_3: 0 - ETA: 1s - loss: 5.0869 - binary_accuracy: 0.7698 -\n",
      "Epoch 10/20\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 3.6192 - binary_accuracy: 0.7755 - auc_3: 0.7419\n",
      "Epoch 11/20\n",
      "125/125 [==============================] - 13s 103ms/step - loss: 4.4952 - binary_accuracy: 0.7750 - auc_3: 0.73532s - loss: 4.7000 - binary_acc\n",
      "Epoch 12/20\n",
      " 93/125 [=====================>........] - ETA: 3s - loss: 3.0146 - binary_accuracy: 0.8021 - auc_3: 0.7803"
     ]
    }
   ],
   "source": [
    "k=0\n",
    "starts_ends = []\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(0, len(aug_lst)):\n",
    "    for j in range(0, len(mod_type)):\n",
    "        print(\"Model: \" + str(k))\n",
    "        data_augmentation = aug_lst[i]\n",
    "        aug_mod, aug_inputs = gen_augmentation(image_size + (3,))\n",
    "        if (j==0):\n",
    "            model = make_basic_model(num_classes=2, x=aug_mod, inputs=aug_inputs)\n",
    "        elif (j==1):\n",
    "            model = make_effB3_model(x=aug_mod, inputs=aug_inputs)\n",
    "        elif (j==2):\n",
    "            model = make_vgg16_model(x=aug_mod, inputs=aug_inputs)\n",
    "        elif (j==3):\n",
    "            model = make_rn152v2_model(x=aug_mod, inputs=aug_inputs)\n",
    "        else:\n",
    "            model = make_dn201_model(x=aug_mod, inputs=aug_inputs)\n",
    "        mdl, eval_lst = execute_model(model, train_ds, test_ds, group_lst[i], k, mod_type[j])\n",
    "        mdl_lst.append(mdl)\n",
    "        eval_all.append(eval_lst)\n",
    "        k += 1\n",
    "        print()\n",
    "        \n",
    "tot_in_sec = time.time() - start_time\n",
    "print(\"--- %s seconds ---\" % (tot_in_sec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7cfed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"id\", \"train_loss\", \"train_bin_acc\", \"train_auc\", \"test_loss\", \"test_bin_acc\", \"test_auc\", \"group\", \"model\"]\n",
    "df_best_model = pd.DataFrame(eval_all,columns=cols)\n",
    "df_best_model = df_best_model.sort_values(\"test_auc\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e6e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee14f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = mdl_lst[df_best_model.loc[0, \"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = test_ds.file_paths\n",
    "\n",
    "def generate_sub_best_model(model, file_paths, save_sub, dtn):\n",
    "    predictions = np.array([])\n",
    "    labels =  np.array([])\n",
    "    for x, y in test_ds:\n",
    "        predictions = np.concatenate([predictions, model.predict(x).ravel()])\n",
    "        labels = np.concatenate([labels, y.numpy().ravel()])\n",
    "    df_solution = pd.DataFrame(data={'file_paths': file_paths, 'predictions': labels})\n",
    "    #df_solution.to_csv('df_solution.csv', index=False)\n",
    "    df_submission = pd.DataFrame(data={'file_paths': file_paths, 'predictions': predictions})\n",
    "    df_submission[\"file_paths\"] = df_submission[\"file_paths\"].apply(lambda x: \n",
    "                                                                    x.replace(\"/home/user/data/test\",\n",
    "                                                                              \"/data/challenges_data/test\"))\n",
    "    \n",
    "    if (save_sub):\n",
    "        df_submission.to_csv('df_submission_'+str(dtn)+'.csv', index=False)\n",
    "        model.save(\"best_model\"+dtn+\".h5\")\n",
    "    return df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f5b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submissions = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4406d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtn = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "df_submission = generate_sub_best_model(mdl, file_paths, save_submissions, dtn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c215de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
