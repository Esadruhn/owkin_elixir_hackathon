{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56ba65bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os.path\n",
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "train_path = '/home/user/data/data/ML/train'\n",
    "validation_path = '/home/user/data/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21f0c21d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Checking the image sizes\n",
    "img = Image.open('/home/user/data/data/ML/train/target_1/tumor_0_9_9178.jpg')\n",
    "print(img.size)\n",
    "\n",
    "image_size = (180,180)\n",
    "batch_size = 32\n",
    "epochs = 4\n",
    "eval_all, mdl_lst, aug_lst = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28920b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomAugment(object):\n",
    "    def __call__(self, image):        \n",
    "        # Random flips and grayscale with some stochasticity\n",
    "        img = self._random_apply(tf.image.flip_left_right, image, p=0.6)\n",
    "        img = self._random_apply(self._color_drop, img, p=0.9)\n",
    "        return img\n",
    "\n",
    "    def _color_drop(self, x):\n",
    "        image = tf.image.rgb_to_grayscale(x)\n",
    "        image = tf.tile(x, [1, 1, 1, 3])\n",
    "        return x\n",
    "    \n",
    "    def _random_apply(self, func, x, p):\n",
    "        return tf.cond(\n",
    "          tf.less(tf.random.uniform([], minval=0, maxval=1, dtype=tf.float32),\n",
    "                  tf.cast(p, tf.float32)),\n",
    "          lambda: func(x),\n",
    "          lambda: x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "405758da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 files belonging to 2 classes.\n",
      "Using 4000 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 15:29:45.440848: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-10 15:29:45.455331: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 15:29:45.455697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 15:29:45.457040: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-10 15:29:45.458234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 15:29:45.458601: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 15:29:45.458934: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 15:29:46.061587: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 15:29:46.061974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 15:29:46.062313: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-10 15:29:46.062574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 126 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
      "2021-11-10 15:29:46.069483: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 126.75M (132907008 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2021-11-10 15:29:46.071120: I tensorflow/stream_executor/cuda/cuda_driver.cc:732] failed to allocate 114.08M (119616512 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=train_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=0,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=validation_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    shuffle=False,\n",
    "    seed=0,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed46c4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(buffer_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b66ab741",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "    # Image augmentation block\n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    # Entry block\n",
    "    x = layers.Rescaling(1.0 / 255)(x)\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x  # Set aside residual\n",
    "\n",
    "    for size in [128, 256, 512, 728]:\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
    "\n",
    "        # Project residual\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual])  # Add back residual\n",
    "        previous_block_activation = x  # Set aside next residual\n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x)\n",
    "    return keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bab09e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_model(train_ds, test_ds, group, seq):\n",
    "\n",
    "    model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(1e-3),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[tf.keras.metrics.BinaryAccuracy(), tf.keras.metrics.AUC()],\n",
    "    )\n",
    "    model.fit(train_ds, epochs=epochs)\n",
    "    eval_lst = [seq]+model.evaluate(train_ds)+model.evaluate(test_ds)+[group]\n",
    "    \n",
    "    return model, eval_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff2c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_lst = [\"basic_flip_rotation\", \"flip_color\", \"flip_color_zoom\"]\n",
    "\n",
    "aug_lst.append(keras.Sequential([\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1)]))\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.Lambda(CustomAugment()),\n",
    "                                 layers.RandomRotation(0.1)]))\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.Lambda(CustomAugment()),\n",
    "                                 layers.RandomRotation(0.1),\n",
    "                                 layers.RandomZoom(0.1)]))\n",
    "\n",
    "aug_lst.append(keras.Sequential([layers.Lambda(CustomAugment()),\n",
    "                                 layers.RandomRotation(0.1),\n",
    "                                 layers.RandomZoom(0.1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7687400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcb93e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(aug_lst)):\n",
    "    data_augmentation = aug_lst[i]\n",
    "    mdl, eval_lst = execute_model(train_ds, test_ds, group_lst[i], i)\n",
    "    mdl_lst.append(mdl)\n",
    "    eval_all.append(eval_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7cfed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=[\"id\", \"train_loss\", \"train_bin_acc\", \"train_auc\", \"test_loss\", \"test_bin_acc\", \"test_auc\", \"group\"]\n",
    "df_best_model = pd.DataFrame(eval_all,columns=cols)\n",
    "df_best_model = df_best_model.sort_values(\"test_auc\", ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9e6e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_model.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee14f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = mdl_lst[df_best_model.loc[0, \"id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05a438",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = test_ds.file_paths\n",
    "\n",
    "def generate_sub_best_model(model, file_paths, save_sub):\n",
    "    predictions = np.array([])\n",
    "    labels =  np.array([])\n",
    "    for x, y in test_ds:\n",
    "        predictions = np.concatenate([predictions, model.predict(x).ravel()])\n",
    "        labels = np.concatenate([labels, y.numpy().ravel()])\n",
    "    df_solution = pd.DataFrame(data={'file_paths': file_paths, 'predictions': labels})\n",
    "    #df_solution.to_csv('df_solution.csv', index=False)\n",
    "    df_submission = pd.DataFrame(data={'file_paths': file_paths, 'predictions': predictions})\n",
    "    df_submission[\"file_paths\"] = df_submission[\"file_paths\"].apply(lambda x: \n",
    "                                                                    x.replace(\"/home/user/data/test\",\n",
    "                                                                              \"/data/challenges_data/test\"))\n",
    "    \n",
    "    if (save_sub):\n",
    "        dtn = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "        df_submission.to_csv('df_submission_'+str(dtn)+'.csv', index=False)\n",
    "    return df_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f5b62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_submissions = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4406d202",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = generate_sub_best_model(mdl, file_paths, save_submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c215de0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d6180f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
