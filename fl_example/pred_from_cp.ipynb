{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import substra\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = substra.Client.from_config_file(\"node_A\")\n",
    "cp_key = \"be1cf90d-929f-4a74-bbd4-d212272f073c\"\n",
    "test_data_path = Path('/') / 'home' / 'user' / 'data' / 'test'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintuples = client.list_traintuple(filters=[f'traintuple:compute_plan_key:{cp_key}'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rank_max = 0\n",
    "tt_key = \"\"\n",
    "\n",
    "for tt in traintuples:\n",
    "    if tt.rank > rank_max:\n",
    "        rank_max = tt.rank\n",
    "        tt_key = tt.key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 17:26:18.855307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-12 17:26:18.868754: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-12 17:26:18.869796: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-12 17:26:18.871428: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-12 17:26:18.874015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-12 17:26:18.875017: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-12 17:26:18.875992: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-12 17:26:19.467312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-12 17:26:19.468345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-12 17:26:19.469290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-11-12 17:26:19.470173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15405 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-12 17:26:23.702354: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-12 17:26:26.430373: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8204\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_15867/1808887671.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m submission_filepath = Path(\n\u001b[0;32m---> 46\u001b[0;31m     __file__).resolve().parents[1] / 'out' / 'df_submission.csv'\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0mdf_submission\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubmission_filepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# get the last traintuple of the compute plan\n",
    "traintuple = client.get_traintuple(tt_key)\n",
    "\n",
    "# Download the associated model\n",
    "model_path = Path(\".\")\n",
    "model_filename = f'model_{traintuple.train.models[0].key}'\n",
    "client.download_model_from_traintuple(traintuple.key, folder=model_path)\n",
    "\n",
    "# SPECIFIC TO YOUR ALGO\n",
    "# -----------------------\n",
    "#\n",
    "# Here we are loading the model that your algo produced\n",
    "# so if you change the algo, for example if you use PyTorch,\n",
    "# then you might need to change this part as well.\n",
    "\n",
    "# Load the model and create predictions: this code depends on the algo code\n",
    "model = keras.models.load_model(str(model_path / model_filename))\n",
    "\n",
    "image_size = (180, 180)\n",
    "batch_size = 32\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    directory=test_data_path,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"binary\",\n",
    "    shuffle=False,\n",
    "    seed=0,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "predictions = np.array([])\n",
    "labels = np.array([])\n",
    "for x, y in test_ds:\n",
    "    predictions = np.concatenate([predictions, model.predict(x).ravel()])\n",
    "    labels = np.concatenate([labels, y.numpy().ravel()])\n",
    "file_paths = test_ds.file_paths\n",
    "\n",
    "df_submission = pd.DataFrame(data={\n",
    "    'file_paths': file_paths,\n",
    "    'predictions': predictions\n",
    "})\n",
    "df_submission[\"file_paths\"] = df_submission[\"file_paths\"].apply(\n",
    "    lambda x: x.replace(\"/home/user/data/test\", \"/data/challenges_data/test\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          file_paths  predictions\n",
      "0  /data/challenges_data/test/target_0/normal_0_1...     0.026310\n",
      "1  /data/challenges_data/test/target_0/normal_0_1...     0.010726\n",
      "2  /data/challenges_data/test/target_0/normal_0_1...     0.129540\n",
      "3  /data/challenges_data/test/target_0/normal_0_1...     0.043004\n",
      "4  /data/challenges_data/test/target_0/normal_0_1...     0.271591\n",
      "Created the file at df_submission.csv\n"
     ]
    }
   ],
   "source": [
    "submission_filepath = Path('.') / 'df_submission.csv'\n",
    "df_submission.to_csv(submission_filepath, index=False)\n",
    "\n",
    "print(df_submission.head())\n",
    "\n",
    "print(f\"Created the file at {submission_filepath}\")\n",
    "\n",
    "# Delete the downloaded model\n",
    "(model_path / model_filename).unlink()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7fe5dd1e410c33e5d9ff3aa59dde107deb54bff875391393c09f6c02d37151a"
  },
  "kernelspec": {
   "display_name": "elixirkernel",
   "language": "python",
   "name": "elixirkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
