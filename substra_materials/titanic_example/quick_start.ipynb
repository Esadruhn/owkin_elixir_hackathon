{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick start\n",
    "\n",
    "Training and testing with only one node.\n",
    "- dataset: Titanic\n",
    "- algo: random forest\n",
    "- tasks: one traintuple and one testtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import substra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.13.0'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "substra.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "assets_directory = Path(\"titanic\") / \"assets\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Registering data samples and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    client = substra.Client(debug=DEBUG)\n",
    "else:\n",
    "    client = substra.Client.from_config_file(\"node_A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset key 27755e01-f736-4bb7-af61-afa4a4040e0a\n"
     ]
    }
   ],
   "source": [
    "permissions = {\n",
    "            'public': False, \n",
    "            'authorized_ids': []\n",
    "}\n",
    "\n",
    "DATASET = {\n",
    "    'name': 'Titanic dataset - Node 1',\n",
    "    'type': 'csv',\n",
    "    'data_opener': assets_directory / 'dataset' / 'opener.py',\n",
    "    'description': assets_directory / 'dataset' / 'description.md',\n",
    "    'permissions': permissions\n",
    "}\n",
    "\n",
    "dataset_key_1 = client.add_dataset(DATASET)\n",
    "print(f'Dataset key {dataset_key_1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding train data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 data samples were registered\n"
     ]
    }
   ],
   "source": [
    "train_data_sample_folder = assets_directory / 'train_data_samples'\n",
    "train_data_sample_paths = list(train_data_sample_folder.glob('*'))\n",
    "train_data_sample_keys = list()\n",
    "\n",
    "for path in train_data_sample_paths:\n",
    "    data_sample_key = client.add_data_sample({\n",
    "        'data_manager_keys': [dataset_key_1],\n",
    "        'test_only': False,\n",
    "        'path': path,\n",
    "    }, local=True)\n",
    "    train_data_sample_keys.append(data_sample_key)\n",
    "\n",
    "print(f\"{len(train_data_sample_keys)} data samples were registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('titanic/assets/train_data_samples')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_sample_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding test data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 data samples were registered\n"
     ]
    }
   ],
   "source": [
    "test_data_sample_folder = assets_directory / 'test_data_samples'\n",
    "test_data_sample_paths = list(test_data_sample_folder.glob('*'))\n",
    "test_data_sample_keys = list()\n",
    "\n",
    "for path in test_data_sample_paths:\n",
    "    data_sample_key = client.add_data_sample({\n",
    "        'data_manager_keys': [dataset_key_1],\n",
    "        'test_only': True,\n",
    "        'path': path,\n",
    "    }, local=True)\n",
    "    test_data_sample_keys.append(data_sample_key)\n",
    "\n",
    "print(f\"{len(test_data_sample_keys)} data samples were registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "OBJECTIVE = {\n",
    "    'name': 'Titanic: Machine Learning From Disaster',\n",
    "    'description': assets_directory / 'objective' / 'description.md',\n",
    "    'metrics_name': 'accuracy',\n",
    "    'metrics': assets_directory / 'objective' / 'metrics.zip',\n",
    "    'permissions': {\n",
    "        'public': False,\n",
    "        'authorized_ids': []\n",
    "    },\n",
    "}\n",
    "\n",
    "METRICS_DOCKERFILE_FILES = [\n",
    "    assets_directory / 'objective' / 'metrics.py',\n",
    "    assets_directory / 'objective' / 'Dockerfile'\n",
    "]\n",
    "\n",
    "archive_path = OBJECTIVE['metrics']\n",
    "with zipfile.ZipFile(archive_path, 'w') as z:\n",
    "    for filepath in METRICS_DOCKERFILE_FILES:\n",
    "        z.write(filepath, arcname=os.path.basename(filepath))\n",
    "        \n",
    "objective_key = client.add_metric({\n",
    "    'name': OBJECTIVE['name'],\n",
    "    'file': assets_directory / 'objective' / 'metrics.zip',\n",
    "    'description': OBJECTIVE['description'],\n",
    "    'permissions': OBJECTIVE['permissions'],\n",
    "})\n",
    "assert objective_key, 'Missing objective key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "ALGO_KEYS_JSON_FILENAME = 'algo_random_forest_keys.json'\n",
    "\n",
    "ALGO = {\n",
    "    'name': 'Titanic: Random Forest',\n",
    "    'description': assets_directory / 'algo_random_forest' / 'description.md',\n",
    "    'permissions': {\n",
    "        'public': False,\n",
    "        'authorized_ids': []\n",
    "    },\n",
    "}\n",
    "\n",
    "ALGO_DOCKERFILE_FILES = [\n",
    "        assets_directory / 'algo_random_forest/algo.py',\n",
    "        assets_directory / 'algo_random_forest/Dockerfile',\n",
    "]\n",
    "\n",
    "archive_path = assets_directory / 'algo_random_forest' / 'algo_random_forest.zip'\n",
    "with zipfile.ZipFile(archive_path, 'w') as z:\n",
    "    for filepath in ALGO_DOCKERFILE_FILES:\n",
    "        z.write(filepath, arcname=os.path.basename(filepath))\n",
    "ALGO['file'] = archive_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo_key = client.add_algo({\n",
    "    'name': ALGO['name'],\n",
    "    'file': ALGO['file'],\n",
    "    'description': ALGO['description'],\n",
    "    'permissions': ALGO['permissions'],\n",
    "    'category': \"ALGO_SIMPLE\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "traintuple_key = client.add_traintuple({\n",
    "    'algo_key': algo_key,\n",
    "    'data_manager_key': dataset_key_1,\n",
    "    'rank': 0,    \n",
    "    'train_data_sample_keys': train_data_sample_keys\n",
    "})\n",
    "assert traintuple_key, 'Missing traintuple key'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "testtuple_key = client.add_testtuple({\n",
    "    'metric_keys': [objective_key],\n",
    "    'traintuple_key': traintuple_key,\n",
    "    'test_data_sample_keys': test_data_sample_keys,\n",
    "    'data_manager_key': dataset_key_1\n",
    "})\n",
    "assert testtuple_key, 'Missing testtuple key'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "testtuple = client.get_testtuple(testtuple_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STATUS_WAITING'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtuple.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eb68084eaa29406b99bf8c108b861acc': 0.8156424581005587}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testtuple.test.perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elixirkernel",
   "language": "python",
   "name": "elixirkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
